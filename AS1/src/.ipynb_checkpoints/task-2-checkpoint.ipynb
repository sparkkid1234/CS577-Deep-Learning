{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import cifar10\n",
    "from keras import layers\n",
    "from keras import models, optimizers\n",
    "from keras.metrics import mse, binary_crossentropy\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('./impl/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from impl.DenseNeuralNet import *\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_spam_data()\n",
    "#X_train, y_train, X_test, y_test = load_spam_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1841, 57)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<?> Normalize t6hen split into validation set or split into val set then normalize?\n",
    "#Rn = normalize then split\n",
    "mean = X_train.mean(axis=0)\n",
    "X_train -= mean\n",
    "std = X_train.std(axis=0)\n",
    "X_train /= std\n",
    "X_val -= mean\n",
    "X_val /= std\n",
    "X_test -= mean\n",
    "X_test /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1656 samples, validate on 1104 samples\n",
      "Epoch 1/500\n",
      "1656/1656 [==============================] - 2s 1ms/step - loss: 0.7671 - acc: 0.5592 - val_loss: 0.7133 - val_acc: 0.5516\n",
      "Epoch 2/500\n",
      "1656/1656 [==============================] - 0s 36us/step - loss: 0.7494 - acc: 0.5537 - val_loss: 0.7056 - val_acc: 0.5399\n",
      "Epoch 3/500\n",
      "1656/1656 [==============================] - 0s 32us/step - loss: 0.7223 - acc: 0.5815 - val_loss: 0.7004 - val_acc: 0.5480\n",
      "Epoch 4/500\n",
      "1656/1656 [==============================] - 0s 27us/step - loss: 0.7170 - acc: 0.5586 - val_loss: 0.6966 - val_acc: 0.5562\n",
      "Epoch 5/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.7263 - acc: 0.5471 - val_loss: 0.6928 - val_acc: 0.5716\n",
      "Epoch 6/500\n",
      "1656/1656 [==============================] - 0s 28us/step - loss: 0.7045 - acc: 0.5634 - val_loss: 0.6897 - val_acc: 0.5725\n",
      "Epoch 7/500\n",
      "1656/1656 [==============================] - 0s 25us/step - loss: 0.6948 - acc: 0.5525 - val_loss: 0.6864 - val_acc: 0.5924\n",
      "Epoch 8/500\n",
      "1656/1656 [==============================] - 0s 27us/step - loss: 0.7197 - acc: 0.5676 - val_loss: 0.6835 - val_acc: 0.5987\n",
      "Epoch 9/500\n",
      "1656/1656 [==============================] - 0s 28us/step - loss: 0.7074 - acc: 0.5604 - val_loss: 0.6805 - val_acc: 0.6123\n",
      "Epoch 10/500\n",
      "1656/1656 [==============================] - 0s 27us/step - loss: 0.7101 - acc: 0.5477 - val_loss: 0.6775 - val_acc: 0.6214\n",
      "Epoch 11/500\n",
      "1656/1656 [==============================] - 0s 28us/step - loss: 0.6920 - acc: 0.5658 - val_loss: 0.6744 - val_acc: 0.6395\n",
      "Epoch 12/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.6956 - acc: 0.5700 - val_loss: 0.6715 - val_acc: 0.6467\n",
      "Epoch 13/500\n",
      "1656/1656 [==============================] - 0s 33us/step - loss: 0.6953 - acc: 0.5580 - val_loss: 0.6691 - val_acc: 0.6621\n",
      "Epoch 14/500\n",
      "1656/1656 [==============================] - 0s 35us/step - loss: 0.6843 - acc: 0.5942 - val_loss: 0.6664 - val_acc: 0.6884\n",
      "Epoch 15/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.6864 - acc: 0.5725 - val_loss: 0.6638 - val_acc: 0.6938\n",
      "Epoch 16/500\n",
      "1656/1656 [==============================] - 0s 40us/step - loss: 0.6917 - acc: 0.5924 - val_loss: 0.6617 - val_acc: 0.6975\n",
      "Epoch 17/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.6690 - acc: 0.6208 - val_loss: 0.6593 - val_acc: 0.7029\n",
      "Epoch 18/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.6758 - acc: 0.5876 - val_loss: 0.6566 - val_acc: 0.7011\n",
      "Epoch 19/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.6696 - acc: 0.6081 - val_loss: 0.6545 - val_acc: 0.7038\n",
      "Epoch 20/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.6753 - acc: 0.5942 - val_loss: 0.6518 - val_acc: 0.7047\n",
      "Epoch 21/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.6729 - acc: 0.6045 - val_loss: 0.6492 - val_acc: 0.7065\n",
      "Epoch 22/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.6810 - acc: 0.5948 - val_loss: 0.6472 - val_acc: 0.7101\n",
      "Epoch 23/500\n",
      "1656/1656 [==============================] - 0s 54us/step - loss: 0.6718 - acc: 0.6190 - val_loss: 0.6446 - val_acc: 0.7147\n",
      "Epoch 24/500\n",
      "1656/1656 [==============================] - 0s 51us/step - loss: 0.6633 - acc: 0.5978 - val_loss: 0.6423 - val_acc: 0.7174\n",
      "Epoch 25/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.6492 - acc: 0.6310 - val_loss: 0.6392 - val_acc: 0.7192\n",
      "Epoch 26/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.6546 - acc: 0.6190 - val_loss: 0.6363 - val_acc: 0.7192\n",
      "Epoch 27/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.6497 - acc: 0.6274 - val_loss: 0.6331 - val_acc: 0.7255\n",
      "Epoch 28/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.6534 - acc: 0.6244 - val_loss: 0.6301 - val_acc: 0.7328\n",
      "Epoch 29/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.6487 - acc: 0.6419 - val_loss: 0.6269 - val_acc: 0.7391\n",
      "Epoch 30/500\n",
      "1656/1656 [==============================] - 0s 40us/step - loss: 0.6423 - acc: 0.6298 - val_loss: 0.6231 - val_acc: 0.7373\n",
      "Epoch 31/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.6471 - acc: 0.6268 - val_loss: 0.6198 - val_acc: 0.7409\n",
      "Epoch 32/500\n",
      "1656/1656 [==============================] - 0s 40us/step - loss: 0.6444 - acc: 0.6286 - val_loss: 0.6164 - val_acc: 0.7464\n",
      "Epoch 33/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.6465 - acc: 0.6316 - val_loss: 0.6127 - val_acc: 0.7518\n",
      "Epoch 34/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.6358 - acc: 0.6335 - val_loss: 0.6086 - val_acc: 0.7545\n",
      "Epoch 35/500\n",
      "1656/1656 [==============================] - 0s 40us/step - loss: 0.6391 - acc: 0.6407 - val_loss: 0.6050 - val_acc: 0.7600\n",
      "Epoch 36/500\n",
      "1656/1656 [==============================] - 0s 51us/step - loss: 0.6261 - acc: 0.6540 - val_loss: 0.6004 - val_acc: 0.7645\n",
      "Epoch 37/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.6205 - acc: 0.6510 - val_loss: 0.5957 - val_acc: 0.7654\n",
      "Epoch 38/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.6256 - acc: 0.6528 - val_loss: 0.5909 - val_acc: 0.7763\n",
      "Epoch 39/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.6244 - acc: 0.6612 - val_loss: 0.5860 - val_acc: 0.7862\n",
      "Epoch 40/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.6035 - acc: 0.6781 - val_loss: 0.5807 - val_acc: 0.7908\n",
      "Epoch 41/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.6153 - acc: 0.6582 - val_loss: 0.5761 - val_acc: 0.7989\n",
      "Epoch 42/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.6109 - acc: 0.6661 - val_loss: 0.5705 - val_acc: 0.7989\n",
      "Epoch 43/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.6106 - acc: 0.6492 - val_loss: 0.5648 - val_acc: 0.8116\n",
      "Epoch 44/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.5909 - acc: 0.6745 - val_loss: 0.5584 - val_acc: 0.8197\n",
      "Epoch 45/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.5880 - acc: 0.6812 - val_loss: 0.5521 - val_acc: 0.8234\n",
      "Epoch 46/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.5951 - acc: 0.7005 - val_loss: 0.5466 - val_acc: 0.8270\n",
      "Epoch 47/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.5840 - acc: 0.7005 - val_loss: 0.5395 - val_acc: 0.8306\n",
      "Epoch 48/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.5817 - acc: 0.7011 - val_loss: 0.5334 - val_acc: 0.8379\n",
      "Epoch 49/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.5834 - acc: 0.7011 - val_loss: 0.5272 - val_acc: 0.8361\n",
      "Epoch 50/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.5823 - acc: 0.7071 - val_loss: 0.5210 - val_acc: 0.8478\n",
      "Epoch 51/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.5758 - acc: 0.7077 - val_loss: 0.5139 - val_acc: 0.8524\n",
      "Epoch 52/500\n",
      "1656/1656 [==============================] - 0s 38us/step - loss: 0.5783 - acc: 0.7156 - val_loss: 0.5072 - val_acc: 0.8542\n",
      "Epoch 53/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.5678 - acc: 0.7114 - val_loss: 0.5003 - val_acc: 0.8596\n",
      "Epoch 54/500\n",
      "1656/1656 [==============================] - 0s 41us/step - loss: 0.5589 - acc: 0.7264 - val_loss: 0.4928 - val_acc: 0.8605\n",
      "Epoch 55/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.5515 - acc: 0.7277 - val_loss: 0.4849 - val_acc: 0.8623\n",
      "Epoch 56/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.5444 - acc: 0.7452 - val_loss: 0.4766 - val_acc: 0.8632\n",
      "Epoch 57/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.5525 - acc: 0.7319 - val_loss: 0.4695 - val_acc: 0.8732\n",
      "Epoch 58/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.5411 - acc: 0.7397 - val_loss: 0.4614 - val_acc: 0.8777\n",
      "Epoch 59/500\n",
      "1656/1656 [==============================] - 0s 41us/step - loss: 0.5412 - acc: 0.7506 - val_loss: 0.4541 - val_acc: 0.8795\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.5241 - acc: 0.7470 - val_loss: 0.4461 - val_acc: 0.8841\n",
      "Epoch 61/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.5295 - acc: 0.7482 - val_loss: 0.4387 - val_acc: 0.8868\n",
      "Epoch 62/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.5062 - acc: 0.7675 - val_loss: 0.4305 - val_acc: 0.8895\n",
      "Epoch 63/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.5156 - acc: 0.7796 - val_loss: 0.4235 - val_acc: 0.8922\n",
      "Epoch 64/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.5272 - acc: 0.7464 - val_loss: 0.4170 - val_acc: 0.8931\n",
      "Epoch 65/500\n",
      "1656/1656 [==============================] - 0s 40us/step - loss: 0.5085 - acc: 0.7633 - val_loss: 0.4109 - val_acc: 0.8958\n",
      "Epoch 66/500\n",
      "1656/1656 [==============================] - 0s 40us/step - loss: 0.4952 - acc: 0.7754 - val_loss: 0.4038 - val_acc: 0.8967\n",
      "Epoch 67/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.4970 - acc: 0.7729 - val_loss: 0.3976 - val_acc: 0.8967\n",
      "Epoch 68/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.4769 - acc: 0.7923 - val_loss: 0.3900 - val_acc: 0.8995\n",
      "Epoch 69/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.4711 - acc: 0.7886 - val_loss: 0.3832 - val_acc: 0.8995\n",
      "Epoch 70/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.4660 - acc: 0.7929 - val_loss: 0.3769 - val_acc: 0.9004\n",
      "Epoch 71/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.4769 - acc: 0.7977 - val_loss: 0.3708 - val_acc: 0.9004\n",
      "Epoch 72/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.4717 - acc: 0.7917 - val_loss: 0.3647 - val_acc: 0.9013\n",
      "Epoch 73/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.4650 - acc: 0.8080 - val_loss: 0.3587 - val_acc: 0.9013\n",
      "Epoch 74/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.4733 - acc: 0.7911 - val_loss: 0.3538 - val_acc: 0.9031\n",
      "Epoch 75/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.4573 - acc: 0.8122 - val_loss: 0.3487 - val_acc: 0.9031\n",
      "Epoch 76/500\n",
      "1656/1656 [==============================] - 0s 54us/step - loss: 0.4578 - acc: 0.7983 - val_loss: 0.3445 - val_acc: 0.9049\n",
      "Epoch 77/500\n",
      "1656/1656 [==============================] - 0s 51us/step - loss: 0.4442 - acc: 0.8194 - val_loss: 0.3397 - val_acc: 0.9049\n",
      "Epoch 78/500\n",
      "1656/1656 [==============================] - 0s 51us/step - loss: 0.4323 - acc: 0.8237 - val_loss: 0.3351 - val_acc: 0.9058\n",
      "Epoch 79/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.4526 - acc: 0.8164 - val_loss: 0.3310 - val_acc: 0.9058\n",
      "Epoch 80/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.4316 - acc: 0.8200 - val_loss: 0.3270 - val_acc: 0.9067\n",
      "Epoch 81/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.4204 - acc: 0.8364 - val_loss: 0.3233 - val_acc: 0.9076\n",
      "Epoch 82/500\n",
      "1656/1656 [==============================] - 0s 38us/step - loss: 0.4312 - acc: 0.8364 - val_loss: 0.3199 - val_acc: 0.9094\n",
      "Epoch 83/500\n",
      "1656/1656 [==============================] - 0s 37us/step - loss: 0.4402 - acc: 0.8152 - val_loss: 0.3173 - val_acc: 0.9094\n",
      "Epoch 84/500\n",
      "1656/1656 [==============================] - 0s 39us/step - loss: 0.4211 - acc: 0.8376 - val_loss: 0.3141 - val_acc: 0.9130\n",
      "Epoch 85/500\n",
      "1656/1656 [==============================] - 0s 52us/step - loss: 0.4135 - acc: 0.8261 - val_loss: 0.3106 - val_acc: 0.9121\n",
      "Epoch 86/500\n",
      "1656/1656 [==============================] - 0s 51us/step - loss: 0.4133 - acc: 0.8412 - val_loss: 0.3078 - val_acc: 0.9130\n",
      "Epoch 87/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.4067 - acc: 0.8436 - val_loss: 0.3051 - val_acc: 0.9130\n",
      "Epoch 88/500\n",
      "1656/1656 [==============================] - 0s 52us/step - loss: 0.4176 - acc: 0.8321 - val_loss: 0.3027 - val_acc: 0.9130\n",
      "Epoch 89/500\n",
      "1656/1656 [==============================] - 0s 55us/step - loss: 0.3995 - acc: 0.8539 - val_loss: 0.3001 - val_acc: 0.9121\n",
      "Epoch 90/500\n",
      "1656/1656 [==============================] - 0s 52us/step - loss: 0.4031 - acc: 0.8357 - val_loss: 0.2976 - val_acc: 0.9121\n",
      "Epoch 91/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.4005 - acc: 0.8388 - val_loss: 0.2953 - val_acc: 0.9121\n",
      "Epoch 92/500\n",
      "1656/1656 [==============================] - 0s 53us/step - loss: 0.3887 - acc: 0.8593 - val_loss: 0.2930 - val_acc: 0.9121\n",
      "Epoch 93/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.3840 - acc: 0.8593 - val_loss: 0.2906 - val_acc: 0.9121\n",
      "Epoch 94/500\n",
      "1656/1656 [==============================] - 0s 39us/step - loss: 0.3888 - acc: 0.8357 - val_loss: 0.2886 - val_acc: 0.9121\n",
      "Epoch 95/500\n",
      "1656/1656 [==============================] - 0s 39us/step - loss: 0.4016 - acc: 0.8333 - val_loss: 0.2869 - val_acc: 0.9130\n",
      "Epoch 96/500\n",
      "1656/1656 [==============================] - 0s 39us/step - loss: 0.4066 - acc: 0.8424 - val_loss: 0.2860 - val_acc: 0.9130\n",
      "Epoch 97/500\n",
      "1656/1656 [==============================] - 0s 40us/step - loss: 0.3587 - acc: 0.8599 - val_loss: 0.2841 - val_acc: 0.9139\n",
      "Epoch 98/500\n",
      "1656/1656 [==============================] - 0s 39us/step - loss: 0.3833 - acc: 0.8448 - val_loss: 0.2825 - val_acc: 0.9149\n",
      "Epoch 99/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.3677 - acc: 0.8581 - val_loss: 0.2806 - val_acc: 0.9139\n",
      "Epoch 100/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.3664 - acc: 0.8665 - val_loss: 0.2791 - val_acc: 0.9139\n",
      "Epoch 101/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.3618 - acc: 0.8551 - val_loss: 0.2775 - val_acc: 0.9130\n",
      "Epoch 102/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.3616 - acc: 0.8617 - val_loss: 0.2763 - val_acc: 0.9130\n",
      "Epoch 103/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.3618 - acc: 0.8563 - val_loss: 0.2753 - val_acc: 0.9121\n",
      "Epoch 104/500\n",
      "1656/1656 [==============================] - 0s 53us/step - loss: 0.3539 - acc: 0.8665 - val_loss: 0.2741 - val_acc: 0.9121\n",
      "Epoch 105/500\n",
      "1656/1656 [==============================] - 0s 52us/step - loss: 0.3662 - acc: 0.8581 - val_loss: 0.2729 - val_acc: 0.9121\n",
      "Epoch 106/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.3484 - acc: 0.8726 - val_loss: 0.2717 - val_acc: 0.9121\n",
      "Epoch 107/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.3656 - acc: 0.8617 - val_loss: 0.2709 - val_acc: 0.9130\n",
      "Epoch 108/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.3565 - acc: 0.8690 - val_loss: 0.2700 - val_acc: 0.9130\n",
      "Epoch 109/500\n",
      "1656/1656 [==============================] - 0s 38us/step - loss: 0.3613 - acc: 0.8702 - val_loss: 0.2692 - val_acc: 0.9130\n",
      "Epoch 110/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.3373 - acc: 0.8708 - val_loss: 0.2682 - val_acc: 0.9130\n",
      "Epoch 111/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.3418 - acc: 0.8756 - val_loss: 0.2674 - val_acc: 0.9130\n",
      "Epoch 112/500\n",
      "1656/1656 [==============================] - 0s 52us/step - loss: 0.3747 - acc: 0.8569 - val_loss: 0.2671 - val_acc: 0.9130\n",
      "Epoch 113/500\n",
      "1656/1656 [==============================] - 0s 52us/step - loss: 0.3418 - acc: 0.8774 - val_loss: 0.2664 - val_acc: 0.9121\n",
      "Epoch 114/500\n",
      "1656/1656 [==============================] - 0s 55us/step - loss: 0.3365 - acc: 0.8750 - val_loss: 0.2657 - val_acc: 0.9121\n",
      "Epoch 115/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.3459 - acc: 0.8798 - val_loss: 0.2650 - val_acc: 0.9130\n",
      "Epoch 116/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.3397 - acc: 0.8696 - val_loss: 0.2643 - val_acc: 0.9130\n",
      "Epoch 117/500\n",
      "1656/1656 [==============================] - 0s 51us/step - loss: 0.3451 - acc: 0.8720 - val_loss: 0.2635 - val_acc: 0.9130\n",
      "Epoch 118/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.3340 - acc: 0.8647 - val_loss: 0.2630 - val_acc: 0.9121\n",
      "Epoch 119/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.3381 - acc: 0.8756 - val_loss: 0.2623 - val_acc: 0.9139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/500\n",
      "1656/1656 [==============================] - 0s 41us/step - loss: 0.3218 - acc: 0.8786 - val_loss: 0.2617 - val_acc: 0.9149\n",
      "Epoch 121/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.3308 - acc: 0.8810 - val_loss: 0.2609 - val_acc: 0.9158\n",
      "Epoch 122/500\n",
      "1656/1656 [==============================] - 0s 39us/step - loss: 0.3220 - acc: 0.8792 - val_loss: 0.2603 - val_acc: 0.9149\n",
      "Epoch 123/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.3254 - acc: 0.8835 - val_loss: 0.2599 - val_acc: 0.9158\n",
      "Epoch 124/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.3248 - acc: 0.8883 - val_loss: 0.2596 - val_acc: 0.9149\n",
      "Epoch 125/500\n",
      "1656/1656 [==============================] - 0s 35us/step - loss: 0.3402 - acc: 0.8804 - val_loss: 0.2592 - val_acc: 0.9149\n",
      "Epoch 126/500\n",
      "1656/1656 [==============================] - 0s 38us/step - loss: 0.3220 - acc: 0.8774 - val_loss: 0.2587 - val_acc: 0.9149\n",
      "Epoch 127/500\n",
      "1656/1656 [==============================] - 0s 38us/step - loss: 0.3145 - acc: 0.8871 - val_loss: 0.2583 - val_acc: 0.9149\n",
      "Epoch 128/500\n",
      "1656/1656 [==============================] - 0s 41us/step - loss: 0.3309 - acc: 0.8871 - val_loss: 0.2580 - val_acc: 0.9149\n",
      "Epoch 129/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.3151 - acc: 0.8913 - val_loss: 0.2575 - val_acc: 0.9149\n",
      "Epoch 130/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.3276 - acc: 0.8925 - val_loss: 0.2572 - val_acc: 0.9158\n",
      "Epoch 131/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.3435 - acc: 0.8671 - val_loss: 0.2570 - val_acc: 0.9167\n",
      "Epoch 132/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.3145 - acc: 0.8853 - val_loss: 0.2568 - val_acc: 0.9167\n",
      "Epoch 133/500\n",
      "1656/1656 [==============================] - 0s 38us/step - loss: 0.3099 - acc: 0.8913 - val_loss: 0.2564 - val_acc: 0.9167\n",
      "Epoch 134/500\n",
      "1656/1656 [==============================] - 0s 37us/step - loss: 0.3292 - acc: 0.8792 - val_loss: 0.2560 - val_acc: 0.9176\n",
      "Epoch 135/500\n",
      "1656/1656 [==============================] - 0s 39us/step - loss: 0.3213 - acc: 0.8883 - val_loss: 0.2560 - val_acc: 0.9194\n",
      "Epoch 136/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.3111 - acc: 0.8913 - val_loss: 0.2557 - val_acc: 0.9194\n",
      "Epoch 137/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.3126 - acc: 0.8901 - val_loss: 0.2554 - val_acc: 0.9194\n",
      "Epoch 138/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.3417 - acc: 0.8786 - val_loss: 0.2550 - val_acc: 0.9185\n",
      "Epoch 139/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.3048 - acc: 0.8949 - val_loss: 0.2548 - val_acc: 0.9176\n",
      "Epoch 140/500\n",
      "1656/1656 [==============================] - 0s 54us/step - loss: 0.3172 - acc: 0.8931 - val_loss: 0.2543 - val_acc: 0.9185\n",
      "Epoch 141/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2995 - acc: 0.8883 - val_loss: 0.2540 - val_acc: 0.9167\n",
      "Epoch 142/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.3040 - acc: 0.8961 - val_loss: 0.2538 - val_acc: 0.9167\n",
      "Epoch 143/500\n",
      "1656/1656 [==============================] - 0s 51us/step - loss: 0.3119 - acc: 0.8901 - val_loss: 0.2535 - val_acc: 0.9176\n",
      "Epoch 144/500\n",
      "1656/1656 [==============================] - 0s 58us/step - loss: 0.2822 - acc: 0.9028 - val_loss: 0.2533 - val_acc: 0.9167\n",
      "Epoch 145/500\n",
      "1656/1656 [==============================] - 0s 54us/step - loss: 0.2969 - acc: 0.8967 - val_loss: 0.2533 - val_acc: 0.9167\n",
      "Epoch 146/500\n",
      "1656/1656 [==============================] - 0s 53us/step - loss: 0.2976 - acc: 0.8907 - val_loss: 0.2532 - val_acc: 0.9167\n",
      "Epoch 147/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.2992 - acc: 0.9028 - val_loss: 0.2530 - val_acc: 0.9167\n",
      "Epoch 148/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.2977 - acc: 0.8955 - val_loss: 0.2525 - val_acc: 0.9176\n",
      "Epoch 149/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.3005 - acc: 0.8992 - val_loss: 0.2519 - val_acc: 0.9176\n",
      "Epoch 150/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.2967 - acc: 0.8979 - val_loss: 0.2516 - val_acc: 0.9176\n",
      "Epoch 151/500\n",
      "1656/1656 [==============================] - 0s 35us/step - loss: 0.3396 - acc: 0.8883 - val_loss: 0.2514 - val_acc: 0.9176\n",
      "Epoch 152/500\n",
      "1656/1656 [==============================] - 0s 32us/step - loss: 0.2972 - acc: 0.8907 - val_loss: 0.2513 - val_acc: 0.9176\n",
      "Epoch 153/500\n",
      "1656/1656 [==============================] - 0s 32us/step - loss: 0.2789 - acc: 0.9028 - val_loss: 0.2511 - val_acc: 0.9176\n",
      "Epoch 154/500\n",
      "1656/1656 [==============================] - 0s 31us/step - loss: 0.3056 - acc: 0.8895 - val_loss: 0.2509 - val_acc: 0.9176\n",
      "Epoch 155/500\n",
      "1656/1656 [==============================] - 0s 32us/step - loss: 0.2862 - acc: 0.8919 - val_loss: 0.2505 - val_acc: 0.9176\n",
      "Epoch 156/500\n",
      "1656/1656 [==============================] - 0s 38us/step - loss: 0.3125 - acc: 0.8919 - val_loss: 0.2502 - val_acc: 0.9176\n",
      "Epoch 157/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.3000 - acc: 0.8949 - val_loss: 0.2500 - val_acc: 0.9176\n",
      "Epoch 158/500\n",
      "1656/1656 [==============================] - 0s 55us/step - loss: 0.3029 - acc: 0.8992 - val_loss: 0.2497 - val_acc: 0.9176\n",
      "Epoch 159/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.2957 - acc: 0.8979 - val_loss: 0.2495 - val_acc: 0.9176\n",
      "Epoch 160/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2802 - acc: 0.8979 - val_loss: 0.2492 - val_acc: 0.9185\n",
      "Epoch 161/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2969 - acc: 0.8979 - val_loss: 0.2490 - val_acc: 0.9176\n",
      "Epoch 162/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.2933 - acc: 0.8986 - val_loss: 0.2485 - val_acc: 0.9176\n",
      "Epoch 163/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.2981 - acc: 0.9064 - val_loss: 0.2481 - val_acc: 0.9185\n",
      "Epoch 164/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.2785 - acc: 0.9016 - val_loss: 0.2481 - val_acc: 0.9185\n",
      "Epoch 165/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.3083 - acc: 0.8937 - val_loss: 0.2481 - val_acc: 0.9185\n",
      "Epoch 166/500\n",
      "1656/1656 [==============================] - 0s 40us/step - loss: 0.2871 - acc: 0.8986 - val_loss: 0.2480 - val_acc: 0.9194\n",
      "Epoch 167/500\n",
      "1656/1656 [==============================] - 0s 38us/step - loss: 0.2908 - acc: 0.9034 - val_loss: 0.2477 - val_acc: 0.9194\n",
      "Epoch 168/500\n",
      "1656/1656 [==============================] - 0s 38us/step - loss: 0.2764 - acc: 0.9022 - val_loss: 0.2477 - val_acc: 0.9203\n",
      "Epoch 169/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.2755 - acc: 0.9022 - val_loss: 0.2474 - val_acc: 0.9203\n",
      "Epoch 170/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.3012 - acc: 0.8992 - val_loss: 0.2471 - val_acc: 0.9203\n",
      "Epoch 171/500\n",
      "1656/1656 [==============================] - 0s 51us/step - loss: 0.2827 - acc: 0.8986 - val_loss: 0.2471 - val_acc: 0.9203\n",
      "Epoch 172/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.2886 - acc: 0.9022 - val_loss: 0.2470 - val_acc: 0.9194\n",
      "Epoch 173/500\n",
      "1656/1656 [==============================] - 0s 40us/step - loss: 0.2879 - acc: 0.8955 - val_loss: 0.2467 - val_acc: 0.9203\n",
      "Epoch 174/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.2897 - acc: 0.9040 - val_loss: 0.2466 - val_acc: 0.9203\n",
      "Epoch 175/500\n",
      "1656/1656 [==============================] - 0s 40us/step - loss: 0.2971 - acc: 0.9010 - val_loss: 0.2466 - val_acc: 0.9203\n",
      "Epoch 176/500\n",
      "1656/1656 [==============================] - 0s 40us/step - loss: 0.2736 - acc: 0.9100 - val_loss: 0.2464 - val_acc: 0.9203\n",
      "Epoch 177/500\n",
      "1656/1656 [==============================] - 0s 35us/step - loss: 0.2739 - acc: 0.8973 - val_loss: 0.2466 - val_acc: 0.9212\n",
      "Epoch 178/500\n",
      "1656/1656 [==============================] - 0s 36us/step - loss: 0.2738 - acc: 0.9082 - val_loss: 0.2464 - val_acc: 0.9212\n",
      "Epoch 179/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1656/1656 [==============================] - 0s 36us/step - loss: 0.2875 - acc: 0.9022 - val_loss: 0.2461 - val_acc: 0.9203\n",
      "Epoch 180/500\n",
      "1656/1656 [==============================] - 0s 34us/step - loss: 0.2777 - acc: 0.9076 - val_loss: 0.2458 - val_acc: 0.9212\n",
      "Epoch 181/500\n",
      "1656/1656 [==============================] - 0s 34us/step - loss: 0.2741 - acc: 0.9088 - val_loss: 0.2458 - val_acc: 0.9212\n",
      "Epoch 182/500\n",
      "1656/1656 [==============================] - 0s 35us/step - loss: 0.2594 - acc: 0.9143 - val_loss: 0.2457 - val_acc: 0.9212\n",
      "Epoch 183/500\n",
      "1656/1656 [==============================] - 0s 34us/step - loss: 0.2942 - acc: 0.8986 - val_loss: 0.2455 - val_acc: 0.9212\n",
      "Epoch 184/500\n",
      "1656/1656 [==============================] - 0s 31us/step - loss: 0.2710 - acc: 0.9070 - val_loss: 0.2450 - val_acc: 0.9212\n",
      "Epoch 185/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.2745 - acc: 0.9028 - val_loss: 0.2451 - val_acc: 0.9212\n",
      "Epoch 186/500\n",
      "1656/1656 [==============================] - 0s 31us/step - loss: 0.2703 - acc: 0.9040 - val_loss: 0.2450 - val_acc: 0.9212\n",
      "Epoch 187/500\n",
      "1656/1656 [==============================] - 0s 31us/step - loss: 0.2642 - acc: 0.9046 - val_loss: 0.2451 - val_acc: 0.9212\n",
      "Epoch 188/500\n",
      "1656/1656 [==============================] - 0s 35us/step - loss: 0.2682 - acc: 0.9064 - val_loss: 0.2450 - val_acc: 0.9212\n",
      "Epoch 189/500\n",
      "1656/1656 [==============================] - 0s 34us/step - loss: 0.2627 - acc: 0.9106 - val_loss: 0.2448 - val_acc: 0.9212\n",
      "Epoch 190/500\n",
      "1656/1656 [==============================] - 0s 37us/step - loss: 0.2744 - acc: 0.9028 - val_loss: 0.2445 - val_acc: 0.9212\n",
      "Epoch 191/500\n",
      "1656/1656 [==============================] - 0s 36us/step - loss: 0.2792 - acc: 0.9064 - val_loss: 0.2444 - val_acc: 0.9212\n",
      "Epoch 192/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.2662 - acc: 0.9118 - val_loss: 0.2441 - val_acc: 0.9212\n",
      "Epoch 193/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.2748 - acc: 0.9112 - val_loss: 0.2442 - val_acc: 0.9212\n",
      "Epoch 194/500\n",
      "1656/1656 [==============================] - 0s 39us/step - loss: 0.2694 - acc: 0.9052 - val_loss: 0.2441 - val_acc: 0.9212\n",
      "Epoch 195/500\n",
      "1656/1656 [==============================] - 0s 38us/step - loss: 0.2521 - acc: 0.9106 - val_loss: 0.2438 - val_acc: 0.9212\n",
      "Epoch 196/500\n",
      "1656/1656 [==============================] - 0s 39us/step - loss: 0.2859 - acc: 0.9052 - val_loss: 0.2434 - val_acc: 0.9230\n",
      "Epoch 197/500\n",
      "1656/1656 [==============================] - 0s 41us/step - loss: 0.2701 - acc: 0.9167 - val_loss: 0.2432 - val_acc: 0.9230\n",
      "Epoch 198/500\n",
      "1656/1656 [==============================] - 0s 38us/step - loss: 0.2679 - acc: 0.9064 - val_loss: 0.2431 - val_acc: 0.9230\n",
      "Epoch 199/500\n",
      "1656/1656 [==============================] - 0s 40us/step - loss: 0.2790 - acc: 0.9070 - val_loss: 0.2427 - val_acc: 0.9230\n",
      "Epoch 200/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.2583 - acc: 0.9040 - val_loss: 0.2423 - val_acc: 0.9221\n",
      "Epoch 201/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2709 - acc: 0.9185 - val_loss: 0.2423 - val_acc: 0.9230\n",
      "Epoch 202/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2662 - acc: 0.9034 - val_loss: 0.2424 - val_acc: 0.9221\n",
      "Epoch 203/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.2757 - acc: 0.9046 - val_loss: 0.2426 - val_acc: 0.9221\n",
      "Epoch 204/500\n",
      "1656/1656 [==============================] - 0s 53us/step - loss: 0.2805 - acc: 0.9028 - val_loss: 0.2425 - val_acc: 0.9221\n",
      "Epoch 205/500\n",
      "1656/1656 [==============================] - 0s 51us/step - loss: 0.2631 - acc: 0.9028 - val_loss: 0.2423 - val_acc: 0.9221\n",
      "Epoch 206/500\n",
      "1656/1656 [==============================] - 0s 52us/step - loss: 0.2741 - acc: 0.9088 - val_loss: 0.2422 - val_acc: 0.9221\n",
      "Epoch 207/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2708 - acc: 0.9046 - val_loss: 0.2421 - val_acc: 0.9221\n",
      "Epoch 208/500\n",
      "1656/1656 [==============================] - 0s 55us/step - loss: 0.2853 - acc: 0.9052 - val_loss: 0.2417 - val_acc: 0.9221\n",
      "Epoch 209/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.2579 - acc: 0.9100 - val_loss: 0.2418 - val_acc: 0.9203\n",
      "Epoch 210/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2715 - acc: 0.9130 - val_loss: 0.2413 - val_acc: 0.9221\n",
      "Epoch 211/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.2865 - acc: 0.9034 - val_loss: 0.2413 - val_acc: 0.9203\n",
      "Epoch 212/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.2594 - acc: 0.9191 - val_loss: 0.2413 - val_acc: 0.9203\n",
      "Epoch 213/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.2679 - acc: 0.9130 - val_loss: 0.2412 - val_acc: 0.9212\n",
      "Epoch 214/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.2641 - acc: 0.9016 - val_loss: 0.2410 - val_acc: 0.9212\n",
      "Epoch 215/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.2691 - acc: 0.9149 - val_loss: 0.2409 - val_acc: 0.9212\n",
      "Epoch 216/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.2664 - acc: 0.9112 - val_loss: 0.2406 - val_acc: 0.9221\n",
      "Epoch 217/500\n",
      "1656/1656 [==============================] - 0s 51us/step - loss: 0.2562 - acc: 0.9106 - val_loss: 0.2407 - val_acc: 0.9203\n",
      "Epoch 218/500\n",
      "1656/1656 [==============================] - 0s 41us/step - loss: 0.2613 - acc: 0.9118 - val_loss: 0.2408 - val_acc: 0.9203\n",
      "Epoch 219/500\n",
      "1656/1656 [==============================] - 0s 40us/step - loss: 0.2578 - acc: 0.9046 - val_loss: 0.2407 - val_acc: 0.9203\n",
      "Epoch 220/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.2650 - acc: 0.9106 - val_loss: 0.2406 - val_acc: 0.9203\n",
      "Epoch 221/500\n",
      "1656/1656 [==============================] - 0s 38us/step - loss: 0.2501 - acc: 0.9112 - val_loss: 0.2405 - val_acc: 0.9203\n",
      "Epoch 222/500\n",
      "1656/1656 [==============================] - 0s 36us/step - loss: 0.2560 - acc: 0.9106 - val_loss: 0.2400 - val_acc: 0.9203\n",
      "Epoch 223/500\n",
      "1656/1656 [==============================] - 0s 35us/step - loss: 0.2942 - acc: 0.9034 - val_loss: 0.2397 - val_acc: 0.9212\n",
      "Epoch 224/500\n",
      "1656/1656 [==============================] - 0s 35us/step - loss: 0.2366 - acc: 0.9185 - val_loss: 0.2399 - val_acc: 0.9203\n",
      "Epoch 225/500\n",
      "1656/1656 [==============================] - 0s 41us/step - loss: 0.2680 - acc: 0.9082 - val_loss: 0.2397 - val_acc: 0.9203\n",
      "Epoch 226/500\n",
      "1656/1656 [==============================] - 0s 33us/step - loss: 0.2715 - acc: 0.9088 - val_loss: 0.2393 - val_acc: 0.9203\n",
      "Epoch 227/500\n",
      "1656/1656 [==============================] - 0s 36us/step - loss: 0.2590 - acc: 0.9124 - val_loss: 0.2393 - val_acc: 0.9203\n",
      "Epoch 228/500\n",
      "1656/1656 [==============================] - 0s 38us/step - loss: 0.2755 - acc: 0.9149 - val_loss: 0.2392 - val_acc: 0.9203\n",
      "Epoch 229/500\n",
      "1656/1656 [==============================] - 0s 37us/step - loss: 0.2677 - acc: 0.9070 - val_loss: 0.2390 - val_acc: 0.9203\n",
      "Epoch 230/500\n",
      "1656/1656 [==============================] - 0s 39us/step - loss: 0.2335 - acc: 0.9215 - val_loss: 0.2389 - val_acc: 0.9212\n",
      "Epoch 231/500\n",
      "1656/1656 [==============================] - 0s 37us/step - loss: 0.2532 - acc: 0.9185 - val_loss: 0.2387 - val_acc: 0.9212\n",
      "Epoch 232/500\n",
      "1656/1656 [==============================] - 0s 41us/step - loss: 0.2366 - acc: 0.9161 - val_loss: 0.2388 - val_acc: 0.9212\n",
      "Epoch 233/500\n",
      "1656/1656 [==============================] - 0s 36us/step - loss: 0.2468 - acc: 0.9167 - val_loss: 0.2388 - val_acc: 0.9212\n",
      "Epoch 234/500\n",
      "1656/1656 [==============================] - 0s 41us/step - loss: 0.2508 - acc: 0.9136 - val_loss: 0.2383 - val_acc: 0.9212\n",
      "Epoch 235/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.2478 - acc: 0.9143 - val_loss: 0.2381 - val_acc: 0.9212\n",
      "Epoch 236/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.2548 - acc: 0.9155 - val_loss: 0.2385 - val_acc: 0.9212\n",
      "Epoch 237/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.2578 - acc: 0.9155 - val_loss: 0.2386 - val_acc: 0.9212\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1656/1656 [==============================] - 0s 53us/step - loss: 0.2602 - acc: 0.9143 - val_loss: 0.2383 - val_acc: 0.9212\n",
      "Epoch 239/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.2508 - acc: 0.9088 - val_loss: 0.2384 - val_acc: 0.9212\n",
      "Epoch 240/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.2428 - acc: 0.9191 - val_loss: 0.2385 - val_acc: 0.9212\n",
      "Epoch 241/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2554 - acc: 0.9191 - val_loss: 0.2383 - val_acc: 0.9212\n",
      "Epoch 242/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.2565 - acc: 0.9124 - val_loss: 0.2381 - val_acc: 0.9212\n",
      "Epoch 243/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2632 - acc: 0.9149 - val_loss: 0.2379 - val_acc: 0.9212\n",
      "Epoch 244/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.2545 - acc: 0.9124 - val_loss: 0.2380 - val_acc: 0.9212\n",
      "Epoch 245/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.2470 - acc: 0.9100 - val_loss: 0.2376 - val_acc: 0.9230\n",
      "Epoch 246/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.2373 - acc: 0.9161 - val_loss: 0.2377 - val_acc: 0.9212\n",
      "Epoch 247/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2532 - acc: 0.9155 - val_loss: 0.2375 - val_acc: 0.9212\n",
      "Epoch 248/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2315 - acc: 0.9197 - val_loss: 0.2377 - val_acc: 0.9212\n",
      "Epoch 249/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.2651 - acc: 0.9112 - val_loss: 0.2374 - val_acc: 0.9212\n",
      "Epoch 250/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2482 - acc: 0.9082 - val_loss: 0.2375 - val_acc: 0.9212\n",
      "Epoch 251/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.2347 - acc: 0.9167 - val_loss: 0.2377 - val_acc: 0.9212\n",
      "Epoch 252/500\n",
      "1656/1656 [==============================] - 0s 39us/step - loss: 0.2483 - acc: 0.9179 - val_loss: 0.2375 - val_acc: 0.9212\n",
      "Epoch 253/500\n",
      "1656/1656 [==============================] - 0s 37us/step - loss: 0.2598 - acc: 0.9112 - val_loss: 0.2375 - val_acc: 0.9212\n",
      "Epoch 254/500\n",
      "1656/1656 [==============================] - 0s 38us/step - loss: 0.2548 - acc: 0.9118 - val_loss: 0.2372 - val_acc: 0.9212\n",
      "Epoch 255/500\n",
      "1656/1656 [==============================] - 0s 41us/step - loss: 0.2442 - acc: 0.9155 - val_loss: 0.2370 - val_acc: 0.9212\n",
      "Epoch 256/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.2588 - acc: 0.9106 - val_loss: 0.2368 - val_acc: 0.9212\n",
      "Epoch 257/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.2577 - acc: 0.9094 - val_loss: 0.2364 - val_acc: 0.9212\n",
      "Epoch 258/500\n",
      "1656/1656 [==============================] - 0s 38us/step - loss: 0.2429 - acc: 0.9185 - val_loss: 0.2365 - val_acc: 0.9212\n",
      "Epoch 259/500\n",
      "1656/1656 [==============================] - 0s 39us/step - loss: 0.2669 - acc: 0.9112 - val_loss: 0.2362 - val_acc: 0.9212\n",
      "Epoch 260/500\n",
      "1656/1656 [==============================] - 0s 39us/step - loss: 0.2396 - acc: 0.9167 - val_loss: 0.2362 - val_acc: 0.9212\n",
      "Epoch 261/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.2487 - acc: 0.9209 - val_loss: 0.2364 - val_acc: 0.9203\n",
      "Epoch 262/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.2599 - acc: 0.9088 - val_loss: 0.2364 - val_acc: 0.9212\n",
      "Epoch 263/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.2480 - acc: 0.9094 - val_loss: 0.2361 - val_acc: 0.9212\n",
      "Epoch 264/500\n",
      "1656/1656 [==============================] - 0s 51us/step - loss: 0.2385 - acc: 0.9197 - val_loss: 0.2360 - val_acc: 0.9221\n",
      "Epoch 265/500\n",
      "1656/1656 [==============================] - 0s 54us/step - loss: 0.2309 - acc: 0.9161 - val_loss: 0.2361 - val_acc: 0.9221\n",
      "Epoch 266/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.2385 - acc: 0.9281 - val_loss: 0.2360 - val_acc: 0.9221\n",
      "Epoch 267/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.2356 - acc: 0.9179 - val_loss: 0.2360 - val_acc: 0.9221\n",
      "Epoch 268/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.2570 - acc: 0.9100 - val_loss: 0.2362 - val_acc: 0.9221\n",
      "Epoch 269/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2368 - acc: 0.9179 - val_loss: 0.2362 - val_acc: 0.9221\n",
      "Epoch 270/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.2308 - acc: 0.9203 - val_loss: 0.2361 - val_acc: 0.9221\n",
      "Epoch 271/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2451 - acc: 0.9191 - val_loss: 0.2361 - val_acc: 0.9221\n",
      "Epoch 272/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.2432 - acc: 0.9118 - val_loss: 0.2361 - val_acc: 0.9221\n",
      "Epoch 273/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2275 - acc: 0.9197 - val_loss: 0.2361 - val_acc: 0.9212\n",
      "Epoch 274/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.2373 - acc: 0.9161 - val_loss: 0.2359 - val_acc: 0.9221\n",
      "Epoch 275/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.2316 - acc: 0.9293 - val_loss: 0.2358 - val_acc: 0.9221\n",
      "Epoch 276/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.2315 - acc: 0.9239 - val_loss: 0.2355 - val_acc: 0.9221\n",
      "Epoch 277/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.2517 - acc: 0.9215 - val_loss: 0.2352 - val_acc: 0.9221\n",
      "Epoch 278/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.2357 - acc: 0.9179 - val_loss: 0.2352 - val_acc: 0.9221\n",
      "Epoch 279/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.2470 - acc: 0.9136 - val_loss: 0.2351 - val_acc: 0.9230\n",
      "Epoch 280/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.2258 - acc: 0.9221 - val_loss: 0.2351 - val_acc: 0.9230\n",
      "Epoch 281/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.2374 - acc: 0.9227 - val_loss: 0.2349 - val_acc: 0.9230\n",
      "Epoch 282/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.2375 - acc: 0.9197 - val_loss: 0.2348 - val_acc: 0.9230\n",
      "Epoch 283/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.2360 - acc: 0.9161 - val_loss: 0.2347 - val_acc: 0.9230\n",
      "Epoch 284/500\n",
      "1656/1656 [==============================] - 0s 40us/step - loss: 0.2354 - acc: 0.9197 - val_loss: 0.2351 - val_acc: 0.9239\n",
      "Epoch 285/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.2351 - acc: 0.9173 - val_loss: 0.2351 - val_acc: 0.9230\n",
      "Epoch 286/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.2273 - acc: 0.9191 - val_loss: 0.2351 - val_acc: 0.9239\n",
      "Epoch 287/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2330 - acc: 0.9185 - val_loss: 0.2350 - val_acc: 0.9230\n",
      "Epoch 288/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.2267 - acc: 0.9197 - val_loss: 0.2347 - val_acc: 0.9230\n",
      "Epoch 289/500\n",
      "1656/1656 [==============================] - 0s 40us/step - loss: 0.2241 - acc: 0.9245 - val_loss: 0.2349 - val_acc: 0.9230\n",
      "Epoch 290/500\n",
      "1656/1656 [==============================] - 0s 39us/step - loss: 0.2417 - acc: 0.9197 - val_loss: 0.2348 - val_acc: 0.9230\n",
      "Epoch 291/500\n",
      "1656/1656 [==============================] - 0s 36us/step - loss: 0.2311 - acc: 0.9257 - val_loss: 0.2346 - val_acc: 0.9230\n",
      "Epoch 292/500\n",
      "1656/1656 [==============================] - 0s 35us/step - loss: 0.2440 - acc: 0.9173 - val_loss: 0.2350 - val_acc: 0.9230\n",
      "Epoch 293/500\n",
      "1656/1656 [==============================] - 0s 31us/step - loss: 0.2425 - acc: 0.9197 - val_loss: 0.2348 - val_acc: 0.9239\n",
      "Epoch 294/500\n",
      "1656/1656 [==============================] - 0s 33us/step - loss: 0.2264 - acc: 0.9203 - val_loss: 0.2347 - val_acc: 0.9239\n",
      "Epoch 295/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.2371 - acc: 0.9185 - val_loss: 0.2345 - val_acc: 0.9230\n",
      "Epoch 296/500\n",
      "1656/1656 [==============================] - 0s 34us/step - loss: 0.2356 - acc: 0.9130 - val_loss: 0.2343 - val_acc: 0.9230\n",
      "Epoch 297/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1656/1656 [==============================] - 0s 33us/step - loss: 0.2480 - acc: 0.9191 - val_loss: 0.2340 - val_acc: 0.9230\n",
      "Epoch 298/500\n",
      "1656/1656 [==============================] - 0s 36us/step - loss: 0.2317 - acc: 0.9185 - val_loss: 0.2339 - val_acc: 0.9221\n",
      "Epoch 299/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.2212 - acc: 0.9275 - val_loss: 0.2339 - val_acc: 0.9221\n",
      "Epoch 300/500\n",
      "1656/1656 [==============================] - 0s 41us/step - loss: 0.2282 - acc: 0.9227 - val_loss: 0.2340 - val_acc: 0.9230\n",
      "Epoch 301/500\n",
      "1656/1656 [==============================] - 0s 39us/step - loss: 0.2285 - acc: 0.9257 - val_loss: 0.2342 - val_acc: 0.9230\n",
      "Epoch 302/500\n",
      "1656/1656 [==============================] - 0s 40us/step - loss: 0.2334 - acc: 0.9239 - val_loss: 0.2339 - val_acc: 0.9230\n",
      "Epoch 303/500\n",
      "1656/1656 [==============================] - 0s 41us/step - loss: 0.2247 - acc: 0.9233 - val_loss: 0.2342 - val_acc: 0.9230\n",
      "Epoch 304/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.2366 - acc: 0.9257 - val_loss: 0.2340 - val_acc: 0.9230\n",
      "Epoch 305/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.2151 - acc: 0.9263 - val_loss: 0.2342 - val_acc: 0.9230\n",
      "Epoch 306/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.2248 - acc: 0.9306 - val_loss: 0.2342 - val_acc: 0.9230\n",
      "Epoch 307/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.2211 - acc: 0.9269 - val_loss: 0.2342 - val_acc: 0.9230\n",
      "Epoch 308/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.2293 - acc: 0.9233 - val_loss: 0.2344 - val_acc: 0.9239\n",
      "Epoch 309/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.2398 - acc: 0.9251 - val_loss: 0.2340 - val_acc: 0.9239\n",
      "Epoch 310/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.2347 - acc: 0.9257 - val_loss: 0.2337 - val_acc: 0.9230\n",
      "Epoch 311/500\n",
      "1656/1656 [==============================] - 0s 51us/step - loss: 0.2332 - acc: 0.9167 - val_loss: 0.2335 - val_acc: 0.9221\n",
      "Epoch 312/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.2493 - acc: 0.9233 - val_loss: 0.2335 - val_acc: 0.9221\n",
      "Epoch 313/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.2454 - acc: 0.9179 - val_loss: 0.2332 - val_acc: 0.9230\n",
      "Epoch 314/500\n",
      "1656/1656 [==============================] - 0s 40us/step - loss: 0.2232 - acc: 0.9287 - val_loss: 0.2336 - val_acc: 0.9230\n",
      "Epoch 315/500\n",
      "1656/1656 [==============================] - 0s 38us/step - loss: 0.2362 - acc: 0.9130 - val_loss: 0.2333 - val_acc: 0.9230\n",
      "Epoch 316/500\n",
      "1656/1656 [==============================] - 0s 41us/step - loss: 0.2395 - acc: 0.9269 - val_loss: 0.2331 - val_acc: 0.9230\n",
      "Epoch 317/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.2191 - acc: 0.9239 - val_loss: 0.2329 - val_acc: 0.9221\n",
      "Epoch 318/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.2277 - acc: 0.9191 - val_loss: 0.2329 - val_acc: 0.9221\n",
      "Epoch 319/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.2377 - acc: 0.9245 - val_loss: 0.2325 - val_acc: 0.9221\n",
      "Epoch 320/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.2176 - acc: 0.9257 - val_loss: 0.2327 - val_acc: 0.9221\n",
      "Epoch 321/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.2320 - acc: 0.9227 - val_loss: 0.2326 - val_acc: 0.9221\n",
      "Epoch 322/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.2240 - acc: 0.9251 - val_loss: 0.2330 - val_acc: 0.9221\n",
      "Epoch 323/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2178 - acc: 0.9300 - val_loss: 0.2331 - val_acc: 0.9221\n",
      "Epoch 324/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.2332 - acc: 0.9179 - val_loss: 0.2330 - val_acc: 0.9221\n",
      "Epoch 325/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.2098 - acc: 0.9300 - val_loss: 0.2333 - val_acc: 0.9221\n",
      "Epoch 326/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.2338 - acc: 0.9185 - val_loss: 0.2330 - val_acc: 0.9221\n",
      "Epoch 327/500\n",
      "1656/1656 [==============================] - 0s 55us/step - loss: 0.2253 - acc: 0.9257 - val_loss: 0.2329 - val_acc: 0.9221\n",
      "Epoch 328/500\n",
      "1656/1656 [==============================] - 0s 56us/step - loss: 0.2262 - acc: 0.9257 - val_loss: 0.2325 - val_acc: 0.9221\n",
      "Epoch 329/500\n",
      "1656/1656 [==============================] - 0s 52us/step - loss: 0.2190 - acc: 0.9233 - val_loss: 0.2329 - val_acc: 0.9221\n",
      "Epoch 330/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2468 - acc: 0.9209 - val_loss: 0.2331 - val_acc: 0.9221\n",
      "Epoch 331/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.2183 - acc: 0.9233 - val_loss: 0.2328 - val_acc: 0.9221\n",
      "Epoch 332/500\n",
      "1656/1656 [==============================] - 0s 41us/step - loss: 0.2303 - acc: 0.9197 - val_loss: 0.2324 - val_acc: 0.9221\n",
      "Epoch 333/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.2252 - acc: 0.9221 - val_loss: 0.2327 - val_acc: 0.9221\n",
      "Epoch 334/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.2245 - acc: 0.9245 - val_loss: 0.2326 - val_acc: 0.9221\n",
      "Epoch 335/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.2204 - acc: 0.9239 - val_loss: 0.2324 - val_acc: 0.9230\n",
      "Epoch 336/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.2240 - acc: 0.9300 - val_loss: 0.2323 - val_acc: 0.9230\n",
      "Epoch 337/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.2259 - acc: 0.9185 - val_loss: 0.2321 - val_acc: 0.9230\n",
      "Epoch 338/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.2377 - acc: 0.9191 - val_loss: 0.2318 - val_acc: 0.9221\n",
      "Epoch 339/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.2164 - acc: 0.9239 - val_loss: 0.2316 - val_acc: 0.9203\n",
      "Epoch 340/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2141 - acc: 0.9245 - val_loss: 0.2317 - val_acc: 0.9212\n",
      "Epoch 341/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.2340 - acc: 0.9239 - val_loss: 0.2312 - val_acc: 0.9221\n",
      "Epoch 342/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.2236 - acc: 0.9245 - val_loss: 0.2312 - val_acc: 0.9221\n",
      "Epoch 343/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.2265 - acc: 0.9203 - val_loss: 0.2309 - val_acc: 0.9230\n",
      "Epoch 344/500\n",
      "1656/1656 [==============================] - 0s 54us/step - loss: 0.2223 - acc: 0.9251 - val_loss: 0.2309 - val_acc: 0.9221\n",
      "Epoch 345/500\n",
      "1656/1656 [==============================] - 0s 53us/step - loss: 0.2197 - acc: 0.9221 - val_loss: 0.2308 - val_acc: 0.9221\n",
      "Epoch 346/500\n",
      "1656/1656 [==============================] - 0s 51us/step - loss: 0.2377 - acc: 0.9239 - val_loss: 0.2305 - val_acc: 0.9221\n",
      "Epoch 347/500\n",
      "1656/1656 [==============================] - 0s 56us/step - loss: 0.2312 - acc: 0.9269 - val_loss: 0.2304 - val_acc: 0.9212\n",
      "Epoch 348/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.2283 - acc: 0.9245 - val_loss: 0.2304 - val_acc: 0.9212\n",
      "Epoch 349/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.2209 - acc: 0.9287 - val_loss: 0.2304 - val_acc: 0.9212\n",
      "Epoch 350/500\n",
      "1656/1656 [==============================] - 0s 41us/step - loss: 0.2250 - acc: 0.9257 - val_loss: 0.2302 - val_acc: 0.9212\n",
      "Epoch 351/500\n",
      "1656/1656 [==============================] - 0s 36us/step - loss: 0.2250 - acc: 0.9185 - val_loss: 0.2298 - val_acc: 0.9212\n",
      "Epoch 352/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.2122 - acc: 0.9275 - val_loss: 0.2298 - val_acc: 0.9221\n",
      "Epoch 353/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.2195 - acc: 0.9257 - val_loss: 0.2295 - val_acc: 0.9212\n",
      "Epoch 354/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.2197 - acc: 0.9269 - val_loss: 0.2292 - val_acc: 0.9221\n",
      "Epoch 355/500\n",
      "1656/1656 [==============================] - 0s 51us/step - loss: 0.2227 - acc: 0.9233 - val_loss: 0.2290 - val_acc: 0.9221\n",
      "Epoch 356/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.2231 - acc: 0.9221 - val_loss: 0.2288 - val_acc: 0.9221\n",
      "Epoch 357/500\n",
      "1656/1656 [==============================] - 0s 54us/step - loss: 0.2261 - acc: 0.9251 - val_loss: 0.2286 - val_acc: 0.9221\n",
      "Epoch 358/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2307 - acc: 0.9239 - val_loss: 0.2284 - val_acc: 0.9221\n",
      "Epoch 359/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.2014 - acc: 0.9293 - val_loss: 0.2285 - val_acc: 0.9239\n",
      "Epoch 360/500\n",
      "1656/1656 [==============================] - 0s 40us/step - loss: 0.2308 - acc: 0.9227 - val_loss: 0.2283 - val_acc: 0.9239\n",
      "Epoch 361/500\n",
      "1656/1656 [==============================] - 0s 35us/step - loss: 0.2285 - acc: 0.9209 - val_loss: 0.2284 - val_acc: 0.9248\n",
      "Epoch 362/500\n",
      "1656/1656 [==============================] - 0s 36us/step - loss: 0.2298 - acc: 0.9155 - val_loss: 0.2285 - val_acc: 0.9248\n",
      "Epoch 363/500\n",
      "1656/1656 [==============================] - 0s 33us/step - loss: 0.2177 - acc: 0.9300 - val_loss: 0.2287 - val_acc: 0.9257\n",
      "Epoch 364/500\n",
      "1656/1656 [==============================] - 0s 38us/step - loss: 0.2291 - acc: 0.9203 - val_loss: 0.2284 - val_acc: 0.9257\n",
      "Epoch 365/500\n",
      "1656/1656 [==============================] - 0s 33us/step - loss: 0.2258 - acc: 0.9203 - val_loss: 0.2284 - val_acc: 0.9248\n",
      "Epoch 366/500\n",
      "1656/1656 [==============================] - 0s 34us/step - loss: 0.2028 - acc: 0.9281 - val_loss: 0.2286 - val_acc: 0.9248\n",
      "Epoch 367/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.2159 - acc: 0.9215 - val_loss: 0.2285 - val_acc: 0.9239\n",
      "Epoch 368/500\n",
      "1656/1656 [==============================] - 0s 37us/step - loss: 0.2214 - acc: 0.9263 - val_loss: 0.2280 - val_acc: 0.9239\n",
      "Epoch 369/500\n",
      "1656/1656 [==============================] - 0s 37us/step - loss: 0.2269 - acc: 0.9209 - val_loss: 0.2281 - val_acc: 0.9248\n",
      "Epoch 370/500\n",
      "1656/1656 [==============================] - 0s 41us/step - loss: 0.2167 - acc: 0.9275 - val_loss: 0.2279 - val_acc: 0.9248\n",
      "Epoch 371/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.2339 - acc: 0.9215 - val_loss: 0.2280 - val_acc: 0.9248\n",
      "Epoch 372/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.2074 - acc: 0.9287 - val_loss: 0.2279 - val_acc: 0.9248\n",
      "Epoch 373/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.2191 - acc: 0.9245 - val_loss: 0.2280 - val_acc: 0.9248\n",
      "Epoch 374/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.2315 - acc: 0.9215 - val_loss: 0.2277 - val_acc: 0.9248\n",
      "Epoch 375/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.2109 - acc: 0.9312 - val_loss: 0.2278 - val_acc: 0.9248\n",
      "Epoch 376/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.2075 - acc: 0.9300 - val_loss: 0.2279 - val_acc: 0.9239\n",
      "Epoch 377/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.2087 - acc: 0.9318 - val_loss: 0.2280 - val_acc: 0.9230\n",
      "Epoch 378/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.2173 - acc: 0.9221 - val_loss: 0.2280 - val_acc: 0.9239\n",
      "Epoch 379/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.2091 - acc: 0.9318 - val_loss: 0.2280 - val_acc: 0.9239\n",
      "Epoch 380/500\n",
      "1656/1656 [==============================] - 0s 40us/step - loss: 0.2199 - acc: 0.9203 - val_loss: 0.2281 - val_acc: 0.9239\n",
      "Epoch 381/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.2218 - acc: 0.9191 - val_loss: 0.2281 - val_acc: 0.9239\n",
      "Epoch 382/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.2172 - acc: 0.9179 - val_loss: 0.2283 - val_acc: 0.9239\n",
      "Epoch 383/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.2159 - acc: 0.9360 - val_loss: 0.2283 - val_acc: 0.9230\n",
      "Epoch 384/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.1977 - acc: 0.9330 - val_loss: 0.2285 - val_acc: 0.9239\n",
      "Epoch 385/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.2212 - acc: 0.9191 - val_loss: 0.2279 - val_acc: 0.9248\n",
      "Epoch 386/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.2064 - acc: 0.9257 - val_loss: 0.2280 - val_acc: 0.9248\n",
      "Epoch 387/500\n",
      "1656/1656 [==============================] - 0s 53us/step - loss: 0.2122 - acc: 0.9293 - val_loss: 0.2281 - val_acc: 0.9239\n",
      "Epoch 388/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2111 - acc: 0.9336 - val_loss: 0.2280 - val_acc: 0.9239\n",
      "Epoch 389/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.2237 - acc: 0.9221 - val_loss: 0.2277 - val_acc: 0.9248\n",
      "Epoch 390/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.2236 - acc: 0.9233 - val_loss: 0.2274 - val_acc: 0.9239\n",
      "Epoch 391/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.2054 - acc: 0.9330 - val_loss: 0.2272 - val_acc: 0.9248\n",
      "Epoch 392/500\n",
      "1656/1656 [==============================] - 0s 41us/step - loss: 0.2116 - acc: 0.9300 - val_loss: 0.2271 - val_acc: 0.9248\n",
      "Epoch 393/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.2258 - acc: 0.9227 - val_loss: 0.2268 - val_acc: 0.9230\n",
      "Epoch 394/500\n",
      "1656/1656 [==============================] - 0s 37us/step - loss: 0.2059 - acc: 0.9287 - val_loss: 0.2268 - val_acc: 0.9230\n",
      "Epoch 395/500\n",
      "1656/1656 [==============================] - 0s 34us/step - loss: 0.2188 - acc: 0.9251 - val_loss: 0.2268 - val_acc: 0.9230\n",
      "Epoch 396/500\n",
      "1656/1656 [==============================] - 0s 38us/step - loss: 0.2143 - acc: 0.9287 - val_loss: 0.2267 - val_acc: 0.9248\n",
      "Epoch 397/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.2127 - acc: 0.9269 - val_loss: 0.2268 - val_acc: 0.9248\n",
      "Epoch 398/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.2186 - acc: 0.9185 - val_loss: 0.2267 - val_acc: 0.9248\n",
      "Epoch 399/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.2083 - acc: 0.9281 - val_loss: 0.2266 - val_acc: 0.9248\n",
      "Epoch 400/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.1986 - acc: 0.9306 - val_loss: 0.2266 - val_acc: 0.9248\n",
      "Epoch 401/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.2148 - acc: 0.9312 - val_loss: 0.2267 - val_acc: 0.9248\n",
      "Epoch 402/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.2189 - acc: 0.9293 - val_loss: 0.2270 - val_acc: 0.9239\n",
      "Epoch 403/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2262 - acc: 0.9257 - val_loss: 0.2266 - val_acc: 0.9239\n",
      "Epoch 404/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.2136 - acc: 0.9306 - val_loss: 0.2268 - val_acc: 0.9239\n",
      "Epoch 405/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.2114 - acc: 0.9227 - val_loss: 0.2268 - val_acc: 0.9239\n",
      "Epoch 406/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.2074 - acc: 0.9324 - val_loss: 0.2269 - val_acc: 0.9239\n",
      "Epoch 407/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.2188 - acc: 0.9203 - val_loss: 0.2267 - val_acc: 0.9239\n",
      "Epoch 408/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2027 - acc: 0.9281 - val_loss: 0.2268 - val_acc: 0.9239\n",
      "Epoch 409/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.2108 - acc: 0.9263 - val_loss: 0.2268 - val_acc: 0.9248\n",
      "Epoch 410/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.2127 - acc: 0.9275 - val_loss: 0.2270 - val_acc: 0.9248\n",
      "Epoch 411/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.2199 - acc: 0.9275 - val_loss: 0.2267 - val_acc: 0.9248\n",
      "Epoch 412/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.2093 - acc: 0.9293 - val_loss: 0.2266 - val_acc: 0.9248\n",
      "Epoch 413/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2067 - acc: 0.9257 - val_loss: 0.2264 - val_acc: 0.9239\n",
      "Epoch 414/500\n",
      "1656/1656 [==============================] - 0s 51us/step - loss: 0.2059 - acc: 0.9336 - val_loss: 0.2265 - val_acc: 0.9239\n",
      "Epoch 415/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1656/1656 [==============================] - 0s 55us/step - loss: 0.2116 - acc: 0.9342 - val_loss: 0.2264 - val_acc: 0.9239\n",
      "Epoch 416/500\n",
      "1656/1656 [==============================] - 0s 56us/step - loss: 0.2306 - acc: 0.9233 - val_loss: 0.2259 - val_acc: 0.9239\n",
      "Epoch 417/500\n",
      "1656/1656 [==============================] - 0s 51us/step - loss: 0.2082 - acc: 0.9300 - val_loss: 0.2258 - val_acc: 0.9239\n",
      "Epoch 418/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.1977 - acc: 0.9281 - val_loss: 0.2260 - val_acc: 0.9239\n",
      "Epoch 419/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.2074 - acc: 0.9360 - val_loss: 0.2262 - val_acc: 0.9239\n",
      "Epoch 420/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.2031 - acc: 0.9293 - val_loss: 0.2262 - val_acc: 0.9239\n",
      "Epoch 421/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.2044 - acc: 0.9312 - val_loss: 0.2262 - val_acc: 0.9239\n",
      "Epoch 422/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.2108 - acc: 0.9293 - val_loss: 0.2262 - val_acc: 0.9239\n",
      "Epoch 423/500\n",
      "1656/1656 [==============================] - 0s 47us/step - loss: 0.1968 - acc: 0.9281 - val_loss: 0.2262 - val_acc: 0.9239\n",
      "Epoch 424/500\n",
      "1656/1656 [==============================] - 0s 51us/step - loss: 0.2141 - acc: 0.9251 - val_loss: 0.2256 - val_acc: 0.9239\n",
      "Epoch 425/500\n",
      "1656/1656 [==============================] - 0s 50us/step - loss: 0.2056 - acc: 0.9287 - val_loss: 0.2255 - val_acc: 0.9239\n",
      "Epoch 426/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.2173 - acc: 0.9348 - val_loss: 0.2255 - val_acc: 0.9239\n",
      "Epoch 427/500\n",
      "1656/1656 [==============================] - 0s 32us/step - loss: 0.1952 - acc: 0.9287 - val_loss: 0.2256 - val_acc: 0.9239\n",
      "Epoch 428/500\n",
      "1656/1656 [==============================] - 0s 33us/step - loss: 0.2089 - acc: 0.9306 - val_loss: 0.2251 - val_acc: 0.9257\n",
      "Epoch 429/500\n",
      "1656/1656 [==============================] - 0s 35us/step - loss: 0.2092 - acc: 0.9287 - val_loss: 0.2250 - val_acc: 0.9239\n",
      "Epoch 430/500\n",
      "1656/1656 [==============================] - 0s 36us/step - loss: 0.2071 - acc: 0.9306 - val_loss: 0.2248 - val_acc: 0.9248\n",
      "Epoch 431/500\n",
      "1656/1656 [==============================] - 0s 37us/step - loss: 0.2047 - acc: 0.9324 - val_loss: 0.2248 - val_acc: 0.9248\n",
      "Epoch 432/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.2046 - acc: 0.9300 - val_loss: 0.2250 - val_acc: 0.9248\n",
      "Epoch 433/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.2106 - acc: 0.9269 - val_loss: 0.2250 - val_acc: 0.9239\n",
      "Epoch 434/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.2152 - acc: 0.9227 - val_loss: 0.2247 - val_acc: 0.9248\n",
      "Epoch 435/500\n",
      "1656/1656 [==============================] - 0s 55us/step - loss: 0.2013 - acc: 0.9312 - val_loss: 0.2248 - val_acc: 0.9248\n",
      "Epoch 436/500\n",
      "1656/1656 [==============================] - 0s 55us/step - loss: 0.2050 - acc: 0.9239 - val_loss: 0.2248 - val_acc: 0.9248\n",
      "Epoch 437/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.2114 - acc: 0.9251 - val_loss: 0.2249 - val_acc: 0.9257\n",
      "Epoch 438/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.2086 - acc: 0.9300 - val_loss: 0.2248 - val_acc: 0.9257\n",
      "Epoch 439/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.2166 - acc: 0.9221 - val_loss: 0.2249 - val_acc: 0.9248\n",
      "Epoch 440/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.2130 - acc: 0.9318 - val_loss: 0.2246 - val_acc: 0.9248\n",
      "Epoch 441/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.2114 - acc: 0.9306 - val_loss: 0.2246 - val_acc: 0.9257\n",
      "Epoch 442/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.2036 - acc: 0.9293 - val_loss: 0.2242 - val_acc: 0.9257\n",
      "Epoch 443/500\n",
      "1656/1656 [==============================] - 0s 40us/step - loss: 0.2141 - acc: 0.9312 - val_loss: 0.2239 - val_acc: 0.9248\n",
      "Epoch 444/500\n",
      "1656/1656 [==============================] - 0s 35us/step - loss: 0.2109 - acc: 0.9306 - val_loss: 0.2243 - val_acc: 0.9257\n",
      "Epoch 445/500\n",
      "1656/1656 [==============================] - 0s 32us/step - loss: 0.2133 - acc: 0.9269 - val_loss: 0.2241 - val_acc: 0.9257\n",
      "Epoch 446/500\n",
      "1656/1656 [==============================] - 0s 33us/step - loss: 0.2067 - acc: 0.9215 - val_loss: 0.2240 - val_acc: 0.9257\n",
      "Epoch 447/500\n",
      "1656/1656 [==============================] - 0s 38us/step - loss: 0.2149 - acc: 0.9287 - val_loss: 0.2239 - val_acc: 0.9257\n",
      "Epoch 448/500\n",
      "1656/1656 [==============================] - 0s 41us/step - loss: 0.1916 - acc: 0.9312 - val_loss: 0.2239 - val_acc: 0.9257\n",
      "Epoch 449/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.1982 - acc: 0.9281 - val_loss: 0.2241 - val_acc: 0.9257\n",
      "Epoch 450/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.1882 - acc: 0.9360 - val_loss: 0.2245 - val_acc: 0.9257\n",
      "Epoch 451/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2061 - acc: 0.9293 - val_loss: 0.2246 - val_acc: 0.9257\n",
      "Epoch 452/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.2031 - acc: 0.9263 - val_loss: 0.2246 - val_acc: 0.9257\n",
      "Epoch 453/500\n",
      "1656/1656 [==============================] - 0s 40us/step - loss: 0.1946 - acc: 0.9318 - val_loss: 0.2249 - val_acc: 0.9257\n",
      "Epoch 454/500\n",
      "1656/1656 [==============================] - 0s 40us/step - loss: 0.2049 - acc: 0.9300 - val_loss: 0.2247 - val_acc: 0.9257\n",
      "Epoch 455/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2120 - acc: 0.9281 - val_loss: 0.2247 - val_acc: 0.9248\n",
      "Epoch 456/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.1885 - acc: 0.9342 - val_loss: 0.2246 - val_acc: 0.9248\n",
      "Epoch 457/500\n",
      "1656/1656 [==============================] - 0s 38us/step - loss: 0.1967 - acc: 0.9330 - val_loss: 0.2243 - val_acc: 0.9248\n",
      "Epoch 458/500\n",
      "1656/1656 [==============================] - 0s 37us/step - loss: 0.1947 - acc: 0.9378 - val_loss: 0.2245 - val_acc: 0.9257\n",
      "Epoch 459/500\n",
      "1656/1656 [==============================] - 0s 44us/step - loss: 0.1893 - acc: 0.9348 - val_loss: 0.2247 - val_acc: 0.9257\n",
      "Epoch 460/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.2103 - acc: 0.9203 - val_loss: 0.2242 - val_acc: 0.9248\n",
      "Epoch 461/500\n",
      "1656/1656 [==============================] - 0s 51us/step - loss: 0.1926 - acc: 0.9306 - val_loss: 0.2243 - val_acc: 0.9257\n",
      "Epoch 462/500\n",
      "1656/1656 [==============================] - 0s 55us/step - loss: 0.2109 - acc: 0.9318 - val_loss: 0.2240 - val_acc: 0.9257\n",
      "Epoch 463/500\n",
      "1656/1656 [==============================] - 0s 51us/step - loss: 0.2004 - acc: 0.9348 - val_loss: 0.2242 - val_acc: 0.9257\n",
      "Epoch 464/500\n",
      "1656/1656 [==============================] - 0s 54us/step - loss: 0.1968 - acc: 0.9312 - val_loss: 0.2244 - val_acc: 0.9257\n",
      "Epoch 465/500\n",
      "1656/1656 [==============================] - 0s 51us/step - loss: 0.2019 - acc: 0.9275 - val_loss: 0.2245 - val_acc: 0.9248\n",
      "Epoch 466/500\n",
      "1656/1656 [==============================] - 0s 49us/step - loss: 0.1997 - acc: 0.9336 - val_loss: 0.2244 - val_acc: 0.9248\n",
      "Epoch 467/500\n",
      "1656/1656 [==============================] - 0s 48us/step - loss: 0.2009 - acc: 0.9293 - val_loss: 0.2242 - val_acc: 0.9248\n",
      "Epoch 468/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.1983 - acc: 0.9330 - val_loss: 0.2241 - val_acc: 0.9248\n",
      "Epoch 469/500\n",
      "1656/1656 [==============================] - 0s 42us/step - loss: 0.2036 - acc: 0.9300 - val_loss: 0.2239 - val_acc: 0.9248\n",
      "Epoch 470/500\n",
      "1656/1656 [==============================] - 0s 46us/step - loss: 0.1986 - acc: 0.9336 - val_loss: 0.2238 - val_acc: 0.9248\n",
      "Epoch 471/500\n",
      "1656/1656 [==============================] - 0s 45us/step - loss: 0.1904 - acc: 0.9300 - val_loss: 0.2238 - val_acc: 0.9248\n",
      "Epoch 472/500\n",
      "1656/1656 [==============================] - 0s 43us/step - loss: 0.1929 - acc: 0.9402 - val_loss: 0.2236 - val_acc: 0.9248\n",
      "Epoch 473/500\n",
      "1656/1656 [==============================] - 0s 36us/step - loss: 0.2056 - acc: 0.9269 - val_loss: 0.2236 - val_acc: 0.9248\n",
      "Epoch 474/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1656/1656 [==============================] - 0s 38us/step - loss: 0.2067 - acc: 0.9348 - val_loss: 0.2234 - val_acc: 0.9248\n",
      "Epoch 475/500\n",
      "1656/1656 [==============================] - 0s 41us/step - loss: 0.1914 - acc: 0.9293 - val_loss: 0.2235 - val_acc: 0.9257\n",
      "Epoch 476/500\n",
      "1656/1656 [==============================] - 0s 39us/step - loss: 0.2105 - acc: 0.9269 - val_loss: 0.2232 - val_acc: 0.9257\n",
      "Epoch 477/500\n",
      "1656/1656 [==============================] - 0s 36us/step - loss: 0.1973 - acc: 0.9312 - val_loss: 0.2232 - val_acc: 0.9257\n",
      "Epoch 478/500\n",
      "1656/1656 [==============================] - 0s 37us/step - loss: 0.1884 - acc: 0.9366 - val_loss: 0.2232 - val_acc: 0.9266\n",
      "Epoch 479/500\n",
      "1656/1656 [==============================] - 0s 33us/step - loss: 0.2038 - acc: 0.9251 - val_loss: 0.2229 - val_acc: 0.9266\n",
      "Epoch 480/500\n",
      "1656/1656 [==============================] - 0s 34us/step - loss: 0.2050 - acc: 0.9324 - val_loss: 0.2224 - val_acc: 0.9257\n",
      "Epoch 481/500\n",
      "1656/1656 [==============================] - 0s 33us/step - loss: 0.2171 - acc: 0.9300 - val_loss: 0.2219 - val_acc: 0.9257\n",
      "Epoch 482/500\n",
      "1656/1656 [==============================] - 0s 35us/step - loss: 0.1888 - acc: 0.9300 - val_loss: 0.2224 - val_acc: 0.9248\n",
      "Epoch 483/500\n",
      "1656/1656 [==============================] - 0s 32us/step - loss: 0.2041 - acc: 0.9354 - val_loss: 0.2224 - val_acc: 0.9248\n",
      "Epoch 484/500\n",
      "1656/1656 [==============================] - 0s 36us/step - loss: 0.2034 - acc: 0.9324 - val_loss: 0.2224 - val_acc: 0.9248\n",
      "Epoch 485/500\n",
      "1656/1656 [==============================] - 0s 32us/step - loss: 0.1946 - acc: 0.9360 - val_loss: 0.2222 - val_acc: 0.9248\n",
      "Epoch 486/500\n",
      "1656/1656 [==============================] - 0s 32us/step - loss: 0.2068 - acc: 0.9209 - val_loss: 0.2221 - val_acc: 0.9248\n",
      "Epoch 487/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.1973 - acc: 0.9312 - val_loss: 0.2219 - val_acc: 0.9248\n",
      "Epoch 488/500\n",
      "1656/1656 [==============================] - 0s 28us/step - loss: 0.2043 - acc: 0.9318 - val_loss: 0.2216 - val_acc: 0.9257\n",
      "Epoch 489/500\n",
      "1656/1656 [==============================] - 0s 26us/step - loss: 0.2004 - acc: 0.9378 - val_loss: 0.2212 - val_acc: 0.9248\n",
      "Epoch 490/500\n",
      "1656/1656 [==============================] - 0s 26us/step - loss: 0.2273 - acc: 0.9251 - val_loss: 0.2208 - val_acc: 0.9257\n",
      "Epoch 491/500\n",
      "1656/1656 [==============================] - 0s 25us/step - loss: 0.1862 - acc: 0.9342 - val_loss: 0.2208 - val_acc: 0.9257\n",
      "Epoch 492/500\n",
      "1656/1656 [==============================] - 0s 25us/step - loss: 0.2082 - acc: 0.9306 - val_loss: 0.2207 - val_acc: 0.9257\n",
      "Epoch 493/500\n",
      "1656/1656 [==============================] - 0s 23us/step - loss: 0.1985 - acc: 0.9342 - val_loss: 0.2207 - val_acc: 0.9248\n",
      "Epoch 494/500\n",
      "1656/1656 [==============================] - 0s 24us/step - loss: 0.2162 - acc: 0.9269 - val_loss: 0.2206 - val_acc: 0.9248\n",
      "Epoch 495/500\n",
      "1656/1656 [==============================] - 0s 25us/step - loss: 0.2126 - acc: 0.9372 - val_loss: 0.2205 - val_acc: 0.9257\n",
      "Epoch 496/500\n",
      "1656/1656 [==============================] - 0s 24us/step - loss: 0.1971 - acc: 0.9348 - val_loss: 0.2203 - val_acc: 0.9248\n",
      "Epoch 497/500\n",
      "1656/1656 [==============================] - 0s 24us/step - loss: 0.2045 - acc: 0.9312 - val_loss: 0.2205 - val_acc: 0.9257\n",
      "Epoch 498/500\n",
      "1656/1656 [==============================] - 0s 25us/step - loss: 0.1980 - acc: 0.9306 - val_loss: 0.2204 - val_acc: 0.9257\n",
      "Epoch 499/500\n",
      "1656/1656 [==============================] - 0s 26us/step - loss: 0.2018 - acc: 0.9330 - val_loss: 0.2204 - val_acc: 0.9248\n",
      "Epoch 500/500\n",
      "1656/1656 [==============================] - 0s 26us/step - loss: 0.1985 - acc: 0.9300 - val_loss: 0.2203 - val_acc: 0.9248\n"
     ]
    }
   ],
   "source": [
    "#This rn uses sgd\n",
    "hyperparams = dict(out_act=\"sigmoid\",learning_rate=0.01,loss = \"binary_crossentropy\")\n",
    "dnn = DNN(X_train.shape[1],1, 4, 64,dropout=True)\n",
    "dnn.fit(X_train, y_train,hyperparams,epochs=500,batch_size=128,validation_data=(X_val,y_val))\n",
    "hist = dnn.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc34003a3c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc38458b208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(hist['acc'],'b',label=\"training accuracy\")\n",
    "plt.plot(hist['val_acc'],'r',label = \"validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title('Loss vs Epochs - Spam dataset')\n",
    "plt.legend()\n",
    "#plt.savefig('Task2_loss_overfit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc35404d8d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc3400f2ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot()\n",
    "plt.plot(hist['loss'],'b',label=\"training loss\")\n",
    "plt.plot(hist['val_loss'],'r',label = \"validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title('Loss vs Epochs - Spam dataset')\n",
    "plt.legend()\n",
    "#plt.savefig('Task2_loss_overfit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1656 samples, validate on 1104 samples\n",
      "Epoch 1/500\n",
      "1656/1656 [==============================] - 0s 286us/step - loss: 0.7367 - acc: 0.5127 - val_loss: 0.6958 - val_acc: 0.5752\n",
      "Epoch 2/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.7327 - acc: 0.5320 - val_loss: 0.6908 - val_acc: 0.5797\n",
      "Epoch 3/500\n",
      "1656/1656 [==============================] - 0s 32us/step - loss: 0.7424 - acc: 0.5326 - val_loss: 0.6867 - val_acc: 0.5861\n",
      "Epoch 4/500\n",
      "1656/1656 [==============================] - 0s 31us/step - loss: 0.7066 - acc: 0.5537 - val_loss: 0.6831 - val_acc: 0.5888\n",
      "Epoch 5/500\n",
      "1656/1656 [==============================] - 0s 32us/step - loss: 0.7066 - acc: 0.5537 - val_loss: 0.6801 - val_acc: 0.5906\n",
      "Epoch 6/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.7218 - acc: 0.5489 - val_loss: 0.6772 - val_acc: 0.5897\n",
      "Epoch 7/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.7179 - acc: 0.5374 - val_loss: 0.6745 - val_acc: 0.5897\n",
      "Epoch 8/500\n",
      "1656/1656 [==============================] - 0s 31us/step - loss: 0.7042 - acc: 0.5725 - val_loss: 0.6722 - val_acc: 0.5888\n",
      "Epoch 9/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.7176 - acc: 0.5465 - val_loss: 0.6695 - val_acc: 0.5897\n",
      "Epoch 10/500\n",
      "1656/1656 [==============================] - 0s 32us/step - loss: 0.6926 - acc: 0.5779 - val_loss: 0.6675 - val_acc: 0.5897\n",
      "Epoch 11/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.6954 - acc: 0.5755 - val_loss: 0.6655 - val_acc: 0.5879\n",
      "Epoch 12/500\n",
      "1656/1656 [==============================] - 0s 31us/step - loss: 0.6903 - acc: 0.5688 - val_loss: 0.6637 - val_acc: 0.5879\n",
      "Epoch 13/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.6923 - acc: 0.5749 - val_loss: 0.6618 - val_acc: 0.5879\n",
      "Epoch 14/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.6920 - acc: 0.5851 - val_loss: 0.6600 - val_acc: 0.5879\n",
      "Epoch 15/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.6980 - acc: 0.5658 - val_loss: 0.6585 - val_acc: 0.5879\n",
      "Epoch 16/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.6758 - acc: 0.6014 - val_loss: 0.6561 - val_acc: 0.5879\n",
      "Epoch 17/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.6687 - acc: 0.6014 - val_loss: 0.6541 - val_acc: 0.5915\n",
      "Epoch 18/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.6749 - acc: 0.5876 - val_loss: 0.6521 - val_acc: 0.5987\n",
      "Epoch 19/500\n",
      "1656/1656 [==============================] - 0s 28us/step - loss: 0.6799 - acc: 0.5948 - val_loss: 0.6502 - val_acc: 0.5969\n",
      "Epoch 20/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.6803 - acc: 0.5845 - val_loss: 0.6485 - val_acc: 0.5942\n",
      "Epoch 21/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.6805 - acc: 0.5894 - val_loss: 0.6467 - val_acc: 0.5924\n",
      "Epoch 22/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.6786 - acc: 0.5984 - val_loss: 0.6449 - val_acc: 0.5951\n",
      "Epoch 23/500\n",
      "1656/1656 [==============================] - 0s 28us/step - loss: 0.6735 - acc: 0.5876 - val_loss: 0.6432 - val_acc: 0.5978\n",
      "Epoch 24/500\n",
      "1656/1656 [==============================] - 0s 33us/step - loss: 0.6641 - acc: 0.5936 - val_loss: 0.6412 - val_acc: 0.5996\n",
      "Epoch 25/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.6738 - acc: 0.5978 - val_loss: 0.6393 - val_acc: 0.6014\n",
      "Epoch 26/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.6712 - acc: 0.6033 - val_loss: 0.6374 - val_acc: 0.5996\n",
      "Epoch 27/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.6789 - acc: 0.5845 - val_loss: 0.6359 - val_acc: 0.6014\n",
      "Epoch 28/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.6601 - acc: 0.6226 - val_loss: 0.6336 - val_acc: 0.6042\n",
      "Epoch 29/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.6582 - acc: 0.6123 - val_loss: 0.6316 - val_acc: 0.6096\n",
      "Epoch 30/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.6645 - acc: 0.6099 - val_loss: 0.6294 - val_acc: 0.6187\n",
      "Epoch 31/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.6617 - acc: 0.6147 - val_loss: 0.6271 - val_acc: 0.6223\n",
      "Epoch 32/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.6600 - acc: 0.5984 - val_loss: 0.6249 - val_acc: 0.6286\n",
      "Epoch 33/500\n",
      "1656/1656 [==============================] - 0s 28us/step - loss: 0.6611 - acc: 0.6033 - val_loss: 0.6227 - val_acc: 0.6341\n",
      "Epoch 34/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.6636 - acc: 0.5924 - val_loss: 0.6206 - val_acc: 0.6449\n",
      "Epoch 35/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.6388 - acc: 0.6365 - val_loss: 0.6175 - val_acc: 0.6476\n",
      "Epoch 36/500\n",
      "1656/1656 [==============================] - 0s 32us/step - loss: 0.6470 - acc: 0.6329 - val_loss: 0.6150 - val_acc: 0.6585\n",
      "Epoch 37/500\n",
      "1656/1656 [==============================] - 0s 33us/step - loss: 0.6421 - acc: 0.6316 - val_loss: 0.6123 - val_acc: 0.6612\n",
      "Epoch 38/500\n",
      "1656/1656 [==============================] - 0s 33us/step - loss: 0.6296 - acc: 0.6389 - val_loss: 0.6089 - val_acc: 0.6748\n",
      "Epoch 39/500\n",
      "1656/1656 [==============================] - 0s 32us/step - loss: 0.6381 - acc: 0.6298 - val_loss: 0.6060 - val_acc: 0.6757\n",
      "Epoch 40/500\n",
      "1656/1656 [==============================] - 0s 32us/step - loss: 0.6366 - acc: 0.6395 - val_loss: 0.6026 - val_acc: 0.6830\n",
      "Epoch 41/500\n",
      "1656/1656 [==============================] - 0s 32us/step - loss: 0.6392 - acc: 0.6298 - val_loss: 0.5992 - val_acc: 0.6857\n",
      "Epoch 42/500\n",
      "1656/1656 [==============================] - 0s 32us/step - loss: 0.6362 - acc: 0.6486 - val_loss: 0.5960 - val_acc: 0.6966\n",
      "Epoch 43/500\n",
      "1656/1656 [==============================] - 0s 31us/step - loss: 0.6270 - acc: 0.6443 - val_loss: 0.5925 - val_acc: 0.7111\n",
      "Epoch 44/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.6259 - acc: 0.6395 - val_loss: 0.5888 - val_acc: 0.7165\n",
      "Epoch 45/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.6375 - acc: 0.6274 - val_loss: 0.5851 - val_acc: 0.7328\n",
      "Epoch 46/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.6184 - acc: 0.6643 - val_loss: 0.5809 - val_acc: 0.7373\n",
      "Epoch 47/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.6257 - acc: 0.6516 - val_loss: 0.5768 - val_acc: 0.7409\n",
      "Epoch 48/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.6198 - acc: 0.6588 - val_loss: 0.5723 - val_acc: 0.7527\n",
      "Epoch 49/500\n",
      "1656/1656 [==============================] - 0s 31us/step - loss: 0.6070 - acc: 0.6775 - val_loss: 0.5675 - val_acc: 0.7600\n",
      "Epoch 50/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.6053 - acc: 0.6624 - val_loss: 0.5623 - val_acc: 0.7645\n",
      "Epoch 51/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.6171 - acc: 0.6588 - val_loss: 0.5579 - val_acc: 0.7690\n",
      "Epoch 52/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.6009 - acc: 0.6848 - val_loss: 0.5531 - val_acc: 0.7808\n",
      "Epoch 53/500\n",
      "1656/1656 [==============================] - 0s 28us/step - loss: 0.6116 - acc: 0.6673 - val_loss: 0.5481 - val_acc: 0.7899\n",
      "Epoch 54/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.5964 - acc: 0.6902 - val_loss: 0.5427 - val_acc: 0.7953\n",
      "Epoch 55/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.6100 - acc: 0.6866 - val_loss: 0.5383 - val_acc: 0.7998\n",
      "Epoch 56/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.5879 - acc: 0.6830 - val_loss: 0.5322 - val_acc: 0.8062\n",
      "Epoch 57/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.5728 - acc: 0.7065 - val_loss: 0.5257 - val_acc: 0.8134\n",
      "Epoch 58/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.5802 - acc: 0.7035 - val_loss: 0.5197 - val_acc: 0.8152\n",
      "Epoch 59/500\n",
      "1656/1656 [==============================] - 0s 33us/step - loss: 0.5776 - acc: 0.6981 - val_loss: 0.5133 - val_acc: 0.8161\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.5813 - acc: 0.7023 - val_loss: 0.5072 - val_acc: 0.8197\n",
      "Epoch 61/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.5679 - acc: 0.7150 - val_loss: 0.5004 - val_acc: 0.8261\n",
      "Epoch 62/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.5635 - acc: 0.7077 - val_loss: 0.4934 - val_acc: 0.8361\n",
      "Epoch 63/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.5416 - acc: 0.7373 - val_loss: 0.4860 - val_acc: 0.8342\n",
      "Epoch 64/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.5590 - acc: 0.7246 - val_loss: 0.4800 - val_acc: 0.8379\n",
      "Epoch 65/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.5521 - acc: 0.7536 - val_loss: 0.4737 - val_acc: 0.8397\n",
      "Epoch 66/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.5524 - acc: 0.7313 - val_loss: 0.4668 - val_acc: 0.8442\n",
      "Epoch 67/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.5335 - acc: 0.7458 - val_loss: 0.4594 - val_acc: 0.8478\n",
      "Epoch 68/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.5259 - acc: 0.7530 - val_loss: 0.4521 - val_acc: 0.8578\n",
      "Epoch 69/500\n",
      "1656/1656 [==============================] - 0s 31us/step - loss: 0.5257 - acc: 0.7385 - val_loss: 0.4447 - val_acc: 0.8605\n",
      "Epoch 70/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.5282 - acc: 0.7512 - val_loss: 0.4378 - val_acc: 0.8632\n",
      "Epoch 71/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.5113 - acc: 0.7597 - val_loss: 0.4305 - val_acc: 0.8650\n",
      "Epoch 72/500\n",
      "1656/1656 [==============================] - 0s 31us/step - loss: 0.5183 - acc: 0.7609 - val_loss: 0.4249 - val_acc: 0.8668\n",
      "Epoch 73/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.5177 - acc: 0.7591 - val_loss: 0.4183 - val_acc: 0.8714\n",
      "Epoch 74/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.5005 - acc: 0.7754 - val_loss: 0.4110 - val_acc: 0.8723\n",
      "Epoch 75/500\n",
      "1656/1656 [==============================] - 0s 32us/step - loss: 0.5055 - acc: 0.7699 - val_loss: 0.4048 - val_acc: 0.8741\n",
      "Epoch 76/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.5254 - acc: 0.7542 - val_loss: 0.3996 - val_acc: 0.8750\n",
      "Epoch 77/500\n",
      "1656/1656 [==============================] - 0s 33us/step - loss: 0.4891 - acc: 0.7760 - val_loss: 0.3934 - val_acc: 0.8768\n",
      "Epoch 78/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.5008 - acc: 0.7808 - val_loss: 0.3880 - val_acc: 0.8795\n",
      "Epoch 79/500\n",
      "1656/1656 [==============================] - 0s 31us/step - loss: 0.5018 - acc: 0.7808 - val_loss: 0.3833 - val_acc: 0.8777\n",
      "Epoch 80/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.4767 - acc: 0.8001 - val_loss: 0.3774 - val_acc: 0.8804\n",
      "Epoch 81/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.4845 - acc: 0.7959 - val_loss: 0.3728 - val_acc: 0.8795\n",
      "Epoch 82/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.4761 - acc: 0.7989 - val_loss: 0.3674 - val_acc: 0.8832\n",
      "Epoch 83/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.4819 - acc: 0.8092 - val_loss: 0.3627 - val_acc: 0.8841\n",
      "Epoch 84/500\n",
      "1656/1656 [==============================] - 0s 28us/step - loss: 0.4508 - acc: 0.8122 - val_loss: 0.3573 - val_acc: 0.8850\n",
      "Epoch 85/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.4545 - acc: 0.7989 - val_loss: 0.3528 - val_acc: 0.8832\n",
      "Epoch 86/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.4495 - acc: 0.8092 - val_loss: 0.3481 - val_acc: 0.8832\n",
      "Epoch 87/500\n",
      "1656/1656 [==============================] - 0s 28us/step - loss: 0.4514 - acc: 0.7983 - val_loss: 0.3440 - val_acc: 0.8832\n",
      "Epoch 88/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.4541 - acc: 0.8200 - val_loss: 0.3403 - val_acc: 0.8832\n",
      "Epoch 89/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.4601 - acc: 0.8231 - val_loss: 0.3367 - val_acc: 0.8859\n",
      "Epoch 90/500\n",
      "1656/1656 [==============================] - 0s 31us/step - loss: 0.4352 - acc: 0.8194 - val_loss: 0.3326 - val_acc: 0.8886\n",
      "Epoch 91/500\n",
      "1656/1656 [==============================] - 0s 31us/step - loss: 0.4457 - acc: 0.8128 - val_loss: 0.3289 - val_acc: 0.8886\n",
      "Epoch 92/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.4343 - acc: 0.8243 - val_loss: 0.3252 - val_acc: 0.8904\n",
      "Epoch 93/500\n",
      "1656/1656 [==============================] - 0s 31us/step - loss: 0.4270 - acc: 0.8279 - val_loss: 0.3217 - val_acc: 0.8904\n",
      "Epoch 94/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.4211 - acc: 0.8339 - val_loss: 0.3186 - val_acc: 0.8931\n",
      "Epoch 95/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.4115 - acc: 0.8370 - val_loss: 0.3151 - val_acc: 0.8931\n",
      "Epoch 96/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.4177 - acc: 0.8370 - val_loss: 0.3124 - val_acc: 0.8931\n",
      "Epoch 97/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.4036 - acc: 0.8370 - val_loss: 0.3096 - val_acc: 0.8931\n",
      "Epoch 98/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.3958 - acc: 0.8466 - val_loss: 0.3067 - val_acc: 0.8940\n",
      "Epoch 99/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.3850 - acc: 0.8502 - val_loss: 0.3037 - val_acc: 0.8940\n",
      "Epoch 100/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.3878 - acc: 0.8442 - val_loss: 0.3010 - val_acc: 0.8958\n",
      "Epoch 101/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.3940 - acc: 0.8454 - val_loss: 0.2989 - val_acc: 0.8967\n",
      "Epoch 102/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.3868 - acc: 0.8551 - val_loss: 0.2969 - val_acc: 0.8967\n",
      "Epoch 103/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.3795 - acc: 0.8521 - val_loss: 0.2944 - val_acc: 0.8967\n",
      "Epoch 104/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.4053 - acc: 0.8351 - val_loss: 0.2928 - val_acc: 0.8976\n",
      "Epoch 105/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.3850 - acc: 0.8539 - val_loss: 0.2907 - val_acc: 0.8976\n",
      "Epoch 106/500\n",
      "1656/1656 [==============================] - 0s 30us/step - loss: 0.3931 - acc: 0.8466 - val_loss: 0.2890 - val_acc: 0.8986\n",
      "Epoch 107/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.3796 - acc: 0.8647 - val_loss: 0.2874 - val_acc: 0.8995\n",
      "Epoch 108/500\n",
      "1656/1656 [==============================] - 0s 29us/step - loss: 0.3797 - acc: 0.8533 - val_loss: 0.2857 - val_acc: 0.8986\n",
      "Epoch 109/500\n",
      " 128/1656 [=>............................] - ETA: 0s - loss: 0.5479 - acc: 0.8516"
     ]
    }
   ],
   "source": [
    "hyperparams = dict(out_act=\"sigmoid\",learning_rate=0.01,loss = \"binary_crossentropy\")\n",
    "dnn = DNN(X_train.shape[1],1, 4, 64,dropout=True)\n",
    "dnn.fit(X_train, y_train,hyperparams,epochs=500,batch_size=128,validation_data=(X_val,y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Acc when dropout using higher lr\n",
    "dnn.model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn.model.save_weights(\"task2_net_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn.model.save('task2_net.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
